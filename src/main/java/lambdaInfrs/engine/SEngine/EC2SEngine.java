/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * Copyright Â© Huan Zhou (SNE, University of Amsterdam) and contributors
 */
package lambdaInfrs.engine.SEngine;

import java.io.File;
import java.util.ArrayList;
import java.util.UUID;

import lambdaInfrs.credential.Credential;
import lambdaInfrs.credential.SSHKeyPair;
import lambdaInfrs.database.BasicDCMetaInfo;
import lambdaInfrs.database.BasicVMMetaInfo;
import lambdaInfrs.database.Database;
import lambdaInfrs.database.EC2.EC2Database;
import lambdaInfrs.engine.VEngine.EC2.EC2VEngine;

import org.apache.log4j.Logger;

import commonTool.CommonTool;
import java.io.IOException;
import java.util.logging.Level;
import topology.dataStructure.EC2.EC2SubTopology;
import topology.dataStructure.EC2.EC2VM;
import topology.description.actual.SubTopology;
import topology.description.actual.SubTopologyInfo;
import topology.description.actual.VM;

public class EC2SEngine extends SEngine {

    private static final Logger logger = Logger.getLogger(EC2SEngine.class);

    /**
     * 1. Update the AMI information. 2. Update the endpoint information. 3. To
     * be completed, check the validity of nodeType.
     * @param subTopologyInfo
     * @param database
     * @return 
     */
    @Override
    public boolean runtimeCheckandUpdate(SubTopologyInfo subTopologyInfo,
            Database database) {

        ///general update
        if (!super.runtimeCheckandUpdate(subTopologyInfo, database)) {
            return false;
        }

        ///Update the endpoint information
        EC2Database ec2Database = (EC2Database) database;
        EC2SubTopology ec2SubTopology = (EC2SubTopology) subTopologyInfo.subTopology;
        String domain = subTopologyInfo.domain.trim().toLowerCase();

        for (int vi = 0; vi < ec2SubTopology.VMs.size(); vi++) {
            EC2VM curVM = ec2SubTopology.VMs.get(vi);
            String vmType = curVM.nodeType.toLowerCase().trim();
            String OS = curVM.OStype.toLowerCase().trim();
            BasicVMMetaInfo ec2VMMetaInfo = null;
            if ((ec2VMMetaInfo = ((BasicVMMetaInfo) ec2Database.getVMMetaInfo(domain, OS, vmType))) == null) {
                logger.error("The EC2 VM meta information for 'OStype' '"
                        + curVM.OStype + "' and 'nodeType' '"
                        + curVM.nodeType + "' in domain '" + domain
                        + "' is not known!");
                return false;
            }
            if (ec2VMMetaInfo.extraInfo != null) {
                curVM.AMI = ec2VMMetaInfo.extraInfo.get("AMI");
            }
            if (curVM.AMI == null) {
                logger.error("There must be 'AMI' information in EC2Database!");
                return false;
            }

            BasicDCMetaInfo ec2DCMetaInfo = null;
            if ((ec2DCMetaInfo = ((BasicDCMetaInfo) ec2Database.getDCMetaInfo(domain))) == null) {
                logger.error("The EC2 datacenter meta information for domain '" + domain
                        + "' is not known!");
                return false;
            }
            if (ec2DCMetaInfo.extraInfo != null) {
                curVM.vpcId = ec2DCMetaInfo.extraInfo.get("vpcId");
                curVM.subnetId = ec2DCMetaInfo.extraInfo.get("subnetId");
                curVM.securityGroupId = ec2DCMetaInfo.extraInfo.get("securityGroupId");
                curVM.routeTableId = ec2DCMetaInfo.extraInfo.get("routeTableId");
                curVM.internetGatewayId = ec2DCMetaInfo.extraInfo.get("internetGatewayId");
            }

        }

        return true;
    }

    @Override
    public boolean createAccessSSHKey(SubTopologyInfo subTopologyInfo,
            Credential credential, Database database) {
        SubTopology ec2SubTopology = subTopologyInfo.subTopology;
        String cp = subTopologyInfo.cloudProvider.trim().toLowerCase();
        String dc = subTopologyInfo.domain.trim().toLowerCase();
        //create a key pair for this sub-topology, if there is none.
        if (ec2SubTopology.accessKeyPair == null) {
            String keyPairId = cp + "-" + dc;
            subTopologyInfo.sshKeyPairId = keyPairId;
            String currentDir = CommonTool.getPathDir(ec2SubTopology.loadingPath);
            String sshKeyDir = currentDir + keyPairId + File.separator;
            File keyDir = new File(sshKeyDir);
            if (!keyDir.exists()) {
                logger.info("There is no ssh key pair for sub-topology '" + ec2SubTopology.topologyName + "'! Generating!");

                String publicKeyId = "publicKey-" + UUID.randomUUID().toString();
                String privateKeyString
                        = EC2VEngine.createSSHKeyPair(subTopologyInfo,
                                credential, publicKeyId);
                if (privateKeyString == null) {
                    logger.error("Unexpected error for creating ssh key pair for sub-topology '" + ec2SubTopology.topologyName + "'!");
                    return false;
                }
                ec2SubTopology.accessKeyPair = new SSHKeyPair();
                ec2SubTopology.accessKeyPair.publicKeyId = publicKeyId;
                ec2SubTopology.accessKeyPair.privateKeyString = privateKeyString;
                ec2SubTopology.accessKeyPair.SSHKeyPairId = keyPairId;

            } else {
                try {
                    logger.info("The ssh key pair for sub-topology '" + ec2SubTopology.topologyName + "' has already exist!");
                    ec2SubTopology.accessKeyPair = new SSHKeyPair();
                    if (!ec2SubTopology.accessKeyPair.loadSSHKeyPair(keyPairId, sshKeyDir)) {
                        logger.error("Error when loading SSH key Pair from " + sshKeyDir);
                        return false;
                    }
                } catch (IOException ex) {
                    logger.error("Error when loading SSH key Pair from " + sshKeyDir, ex);
                    return false;
                }
            }

        }
        return true;
    }

    @Override
    public boolean provision(SubTopologyInfo subTopologyInfo,
            Credential credential, Database database) {
        /////Create a common Subnet if there is a VM do not specify the VPC id etc.
        ArrayList<VM> vms = subTopologyInfo.subTopology.getVMsinSubClass();
        boolean needCommonSubnet = false;
        if (vms != null) {
            for (int vi = 0; vi < vms.size(); vi++) {
                EC2VM curVM = (EC2VM) vms.get(vi);
                if (curVM.vpcId == null
                        || curVM.subnetId == null
                        || curVM.securityGroupId == null
                        || curVM.routeTableId == null
                        || curVM.internetGatewayId == null) {
                    needCommonSubnet = true;
                    break;
                }
            }
        }
        if (needCommonSubnet) {
            if (!EC2VEngine.createCommonSubnet(subTopologyInfo, credential)) {
                logger.error("Cannot create common Subnet!");
                subTopologyInfo.logsInfo.put("ERROR", "Cannot create common Subnet!");
                return false;
            }
        }
        if (super.provision(subTopologyInfo, credential, database)) {
            return true;
        } else {
            return false;
        }
    }

    @Override
    public boolean supportStop(SubTopologyInfo subTopologyInfo) {
        return true;
    }

    @Override
    public boolean delete(SubTopologyInfo subTopologyInfo,
            Credential credential, Database database) {
        ////leverage VEngine to delete all the VMs
        if (!super.delete(subTopologyInfo, credential, database)) {
            return false;
        }

        if (subTopologyInfo.topology.startsWith("_tmp_")) {
            return true;
        }

        if (((EC2SubTopology) (subTopologyInfo.subTopology)).WhetherCreateVPC.equalsIgnoreCase("true")) {
            if (!EC2VEngine.deleteVPC(subTopologyInfo, credential)) {
                return false;
            }
        }

        return true;
    }

}
